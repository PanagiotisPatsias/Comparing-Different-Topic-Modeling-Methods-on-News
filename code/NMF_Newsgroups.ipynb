{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from octis.models.NMF import NMF\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  category\n",
      "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...         7\n",
      "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...         4\n",
      "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...         4\n",
      "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...         1\n",
      "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...        14\n"
     ]
    }
   ],
   "source": [
    "# For 20 Newsgroups dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# Convert the newsgroups data into a pandas DataFrame with 'content' and 'category' columns\n",
    "df_newsgroups_train = pd.DataFrame({\n",
    "    'content': newsgroups_train.data,    \n",
    "    'category': newsgroups_train.target  \n",
    "})\n",
    "\n",
    "\n",
    "df_labels = df_newsgroups_train['category']  \n",
    "df_texts = df_newsgroups_train['content']\n",
    "\n",
    "# Display the first few rows to check the structure\n",
    "print(df_newsgroups_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 20 Newsgroups dataset\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# Convert the newsgroups data into a pandas DataFrame with 'content' and 'category' columns\n",
    "df_newsgroups_test = pd.DataFrame({\n",
    "    'content': newsgroups_train.data,    \n",
    "    'category': newsgroups_train.target  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/patsias/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if you haven't already\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# Define the preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation using regex\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text) \n",
    "    \n",
    "    # Tokenize words, remove stopwords, and convert back to string\n",
    "    words = text.split() \n",
    "    words = [word for word in words if word.lower() not in stop_words]  \n",
    "    \n",
    "    # Return preprocessed text as a single string\n",
    "    return \" \".join(words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function\n",
    "df_newsgroups_train['processed_text'] = df_newsgroups_train['content'].apply(preprocess_text)\n",
    "\n",
    "# Tokenize the text into sets of words\n",
    "df_newsgroups_train['tok'] = df_newsgroups_train['processed_text'].apply(lambda x: set(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function\n",
    "df_newsgroups_test['processed_text'] = df_newsgroups_test['content'].apply(preprocess_text)\n",
    "\n",
    "# Tokenize the text into sets of words\n",
    "df_newsgroups_test['tok'] = df_newsgroups_test['processed_text'].apply(lambda x: set(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newsgroups_train['div'] = 'train'\n",
    "df_newsgroups_test['div'] = 'test'\n",
    "\n",
    "# Merge back train and test into one dataframe\n",
    "group_news_split = pd.concat([df_newsgroups_train, df_newsgroups_test]).reset_index(drop=True)\n",
    "\n",
    "# Create a Gensim dictionary for tokenized words\n",
    "train_docs = group_news_split[group_news_split['div'] == 'train'].tok.to_numpy()\n",
    "dictionary = gensim.corpora.Dictionary(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.json has been successfully created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs('newgroups_octis', exist_ok=True)\n",
    "\n",
    "# Save the vocabulary (for OCTIS)\n",
    "vocab_length = len(dictionary)\n",
    "with open(\"newgroups_octis/vocabulary.txt\", \"w\", encoding='utf8') as f:\n",
    "    for i in range(vocab_length):\n",
    "        f.write(dictionary[i] + '\\n')\n",
    "\n",
    "# Create Bag-of-Words (BoW) representation\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in group_news_split['tok']]\n",
    "group_news_split['corpus'] = bow_corpus\n",
    "\n",
    "# Save the corpus as 'corpus.tsv'\n",
    "group_news_split[['processed_text', 'div', 'category']].to_csv(\"newgroups_octis/corpus.tsv\", sep='\\t', index=False, header=False)\n",
    "\n",
    "# Create metadata.json for categories\n",
    "# Extract labels from your dataframe\n",
    "labels = group_news_split['category'].tolist()\n",
    "\n",
    "# Write labels to metadata.json\n",
    "metadata = {\"labels\": labels}\n",
    "with open(\"newgroups_octis/metadata.json\", \"w\") as outfile:\n",
    "    json.dump(metadata, outfile)\n",
    "\n",
    "print(\"metadata.json has been successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for purity and normalized mutual information (NMI)\n",
    "def q_metrics(y_true, y_pred):\n",
    "    contigency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    purity = np.sum(np.amax(contigency_matrix, axis=0)) / np.sum(contigency_matrix)\n",
    "    print('Purity Score:', purity)\n",
    "    print('NMI:', metrics.normalized_mutual_info_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity Score: 0.1789817924695068\n",
      "NMI: 0.16567547968480673\n",
      "Coherence Score: 0.6193236452839318\n",
      "w_max_iter : 50 ; kappa : 1.0 ; h_max_iter : 50 \n",
      "Purity Score: 0.10544458193388721\n",
      "NMI: 0.04972415962855697\n",
      "Coherence Score: 0.6745162259631792\n",
      "w_max_iter : 50 ; kappa : 2.0 ; h_max_iter : 50 \n",
      "Purity Score: 0.07274173590242178\n",
      "NMI: 0.011530095253093928\n",
      "Coherence Score: 0.6411036142308827\n",
      "w_max_iter : 50 ; kappa : 3.0 ; h_max_iter : 50 \n",
      "Purity Score: 0.10995227152200814\n",
      "NMI: 0.09426075586114431\n",
      "Coherence Score: 0.6798130037164912\n",
      "w_max_iter : 50 ; kappa : 1.0 ; h_max_iter : 100 \n",
      "Purity Score: 0.09483825349124977\n",
      "NMI: 0.03194744875526283\n",
      "Coherence Score: 0.6731224063858837\n",
      "w_max_iter : 50 ; kappa : 2.0 ; h_max_iter : 100 \n",
      "Purity Score: 0.0751281598020152\n",
      "NMI: 0.013003094267862699\n",
      "Coherence Score: 0.6075570114700269\n",
      "w_max_iter : 50 ; kappa : 3.0 ; h_max_iter : 100 \n",
      "Purity Score: 0.1750928053738731\n",
      "NMI: 0.15260730264775357\n",
      "Coherence Score: 0.6309174890089836\n",
      "w_max_iter : 50 ; kappa : 1.0 ; h_max_iter : 200 \n",
      "Purity Score: 0.10924518295916563\n",
      "NMI: 0.048906025758479785\n",
      "Coherence Score: 0.6992718675342952\n",
      "w_max_iter : 50 ; kappa : 2.0 ; h_max_iter : 200 \n",
      "Purity Score: 0.08184550114901891\n",
      "NMI: 0.015824998255899555\n",
      "Coherence Score: 0.6403771377500522\n",
      "w_max_iter : 50 ; kappa : 3.0 ; h_max_iter : 200 \n",
      "Purity Score: 0.09846208237581758\n",
      "NMI: 0.0794668576104552\n",
      "Coherence Score: 0.6405465247755959\n",
      "w_max_iter : 100 ; kappa : 1.0 ; h_max_iter : 50 \n",
      "Purity Score: 0.0964292027576454\n",
      "NMI: 0.03264746306996987\n",
      "Coherence Score: 0.6756399816324178\n",
      "w_max_iter : 100 ; kappa : 2.0 ; h_max_iter : 50 \n",
      "Purity Score: 0.08299452006363797\n",
      "NMI: 0.01920085369655621\n",
      "Coherence Score: 0.633683618425059\n",
      "w_max_iter : 100 ; kappa : 3.0 ; h_max_iter : 50 \n",
      "Purity Score: 0.09634081668729008\n",
      "NMI: 0.08021850415074004\n",
      "Coherence Score: 0.6615893854747581\n",
      "w_max_iter : 100 ; kappa : 1.0 ; h_max_iter : 100 \n",
      "Purity Score: 0.12073537210535619\n",
      "NMI: 0.04979114506381154\n",
      "Coherence Score: 0.6844636827501427\n",
      "w_max_iter : 100 ; kappa : 2.0 ; h_max_iter : 100 \n",
      "Purity Score: 0.08944670319957575\n",
      "NMI: 0.02109447017791797\n",
      "Coherence Score: 0.6255215312205681\n",
      "w_max_iter : 100 ; kappa : 3.0 ; h_max_iter : 100 \n",
      "Purity Score: 0.1545872370514407\n",
      "NMI: 0.13062739875982274\n",
      "Coherence Score: 0.6869199858578108\n",
      "w_max_iter : 100 ; kappa : 1.0 ; h_max_iter : 200 \n",
      "Purity Score: 0.09448470920982853\n",
      "NMI: 0.03418882310092675\n",
      "Coherence Score: 0.6308530220204855\n",
      "w_max_iter : 100 ; kappa : 2.0 ; h_max_iter : 200 \n",
      "Purity Score: 0.077337811560898\n",
      "NMI: 0.018462631216144856\n",
      "Coherence Score: 0.6041324289066491\n",
      "w_max_iter : 100 ; kappa : 3.0 ; h_max_iter : 200 \n",
      "Purity Score: 0.21345235990807848\n",
      "NMI: 0.17111840605785492\n",
      "Coherence Score: 0.6637763956163517\n",
      "w_max_iter : 200 ; kappa : 1.0 ; h_max_iter : 50 \n",
      "Purity Score: 0.09545695598373696\n",
      "NMI: 0.032696913790051435\n",
      "Coherence Score: 0.6204754463096518\n",
      "w_max_iter : 200 ; kappa : 2.0 ; h_max_iter : 50 \n",
      "Purity Score: 0.07459784337988333\n",
      "NMI: 0.011025797526342276\n",
      "Coherence Score: 0.6390771791631737\n",
      "w_max_iter : 200 ; kappa : 3.0 ; h_max_iter : 50 \n",
      "Purity Score: 0.14893052854870073\n",
      "NMI: 0.14689290421676668\n",
      "Coherence Score: 0.6365611749144213\n",
      "w_max_iter : 200 ; kappa : 1.0 ; h_max_iter : 100 \n",
      "Purity Score: 0.09872724058688351\n",
      "NMI: 0.03273629155929108\n",
      "Coherence Score: 0.6167406013620833\n",
      "w_max_iter : 200 ; kappa : 2.0 ; h_max_iter : 100 \n",
      "Purity Score: 0.08476224147074421\n",
      "NMI: 0.02230416928433708\n",
      "Coherence Score: 0.6745954936709608\n",
      "w_max_iter : 200 ; kappa : 3.0 ; h_max_iter : 100 \n",
      "Purity Score: 0.10473749337104472\n",
      "NMI: 0.09172408025517866\n",
      "Coherence Score: 0.6411063155427954\n",
      "w_max_iter : 200 ; kappa : 1.0 ; h_max_iter : 200 \n",
      "Purity Score: 0.0972246773908432\n",
      "NMI: 0.03597203953070644\n",
      "Coherence Score: 0.684523210461936\n",
      "w_max_iter : 200 ; kappa : 2.0 ; h_max_iter : 200 \n",
      "Purity Score: 0.07724942549054269\n",
      "NMI: 0.014448472265401278\n",
      "Coherence Score: 0.6406618552459866\n",
      "w_max_iter : 200 ; kappa : 3.0 ; h_max_iter : 200 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the dataset prepared for OCTIS\n",
    "newgroups_dataset = Dataset()\n",
    "newgroups_dataset.load_custom_dataset_from_folder('newgroups_octis')\n",
    "\n",
    "# Define and train NMF model\n",
    "def calculate_coherence_score(num_topics, kappa, w_max_iter, h_max_iter):\n",
    "    model = NMF(num_topics=num_topics, chunksize=2000, passes=10, kappa=kappa,\n",
    "                minimum_probability=0.01, w_max_iter=w_max_iter,\n",
    "                w_stop_condition=0.0001, h_max_iter=h_max_iter, h_stop_condition=0.001,\n",
    "                eval_every=10, normalize=True)\n",
    "\n",
    "    # Train the model\n",
    "    nmf_output = model.train_model(newgroups_dataset)\n",
    "\n",
    "    # Get the test set results (document-topic matrix)\n",
    "    test_res = nmf_output['test-topic-document-matrix'].T\n",
    "    pred = [np.argmax(res) for res in test_res]\n",
    "\n",
    "    # Load true labels from the dataset\n",
    "    df = pd.read_csv(\"newgroups_octis/corpus.tsv\", sep='\\t', header=None)\n",
    "    y_true = df[df[1] == 'test'][2].values \n",
    "\n",
    "    # Evaluate metrics\n",
    "    q_metrics(y_true, pred)\n",
    "\n",
    "    # # Calculate Coherence\n",
    "    coherence = Coherence(texts=newgroups_dataset.get_corpus(), topk=10, measure='c_v')\n",
    "    coherence_score = coherence.score(nmf_output)\n",
    "    print(f\"Coherence Score: {coherence_score}\")\n",
    "\n",
    "    return coherence_score\n",
    "\n",
    "#list containing various hyperparameters\n",
    "kappa = [1.0, 2.0,3.0]\n",
    "w_max_iter = [50, 100, 200]\n",
    "h_max_iter = [50, 100, 200]\n",
    "\n",
    "\n",
    "for w in w_max_iter:\n",
    "    for h in h_max_iter:\n",
    "        for k in kappa:\n",
    "            calculate_coherence_score(num_topics=20, kappa=k, w_max_iter=w, h_max_iter=h)   \n",
    "            print(f\"w_max_iter : {w} ; kappa : {k} ; h_max_iter : {h} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity Score: 0.07795651405338519\n",
      "NMI: 0.014185867877603306\n",
      "Coherence Score: 0.6520518553728814\n"
     ]
    }
   ],
   "source": [
    "# w_max_iter : 10 ; kappa : 1.0 ; h_max_iter : 20\n",
    "model=NMF(num_topics=20, chunksize=2000, passes=10, kappa=3.0,\n",
    "                minimum_probability=0.01, w_max_iter=100,\n",
    "                w_stop_condition=0.0001, h_max_iter=200, h_stop_condition=0.001,\n",
    "                eval_every=10, normalize=True)\n",
    "\n",
    "newgroups = Dataset()\n",
    "newgroups.load_custom_dataset_from_folder('newgroups_octis')\n",
    "nmf_output = model.train_model(newgroups)\n",
    "\n",
    "test_res = nmf_output['test-topic-document-matrix'].T\n",
    "pred = [np.argmax(res) for res in test_res]\n",
    "\n",
    "# Load true labels from the dataset\n",
    "df = pd.read_csv(\"newgroups_octis/corpus.tsv\", sep='\\t', header=None)\n",
    "y_true = df[df[1] == 'test'][2].values  \n",
    "\n",
    "y_pred = pred\n",
    "q_metrics(y_true, y_pred)\n",
    "\n",
    "\n",
    "# evaluate model using Topic Coherence score\n",
    "coherence = Coherence(texts=newgroups_dataset.get_corpus(), topk=10, measure='c_v')\n",
    "coherence_score = coherence.score(nmf_output)\n",
    "print(f\"Coherence Score: {coherence_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t Counter({9: 13, 15: 12, 7: 12, 4: 12, 11: 12, 0: 11, 5: 10, 17: 10, 19: 10, 14: 9, 16: 9, 12: 8, 6: 8, 1: 8, 10: 7, 3: 7, 18: 7, 2: 6, 8: 5, 13: 5})\n",
      "1 \t Counter({12: 102, 10: 99, 3: 95, 7: 94, 9: 91, 6: 91, 17: 90, 14: 86, 8: 85, 0: 84, 13: 83, 16: 80, 15: 79, 18: 78, 11: 74, 1: 72, 4: 71, 2: 71, 5: 61, 19: 48})\n",
      "2 \t Counter({5: 19, 8: 9, 9: 8, 15: 7, 1: 7, 18: 6, 11: 5, 2: 5, 12: 4, 6: 4, 0: 4, 7: 3, 4: 3, 17: 3, 10: 3, 14: 3, 3: 3, 19: 3, 13: 2, 16: 1})\n",
      "3 \t Counter({14: 11, 16: 10, 4: 6, 8: 6, 13: 6, 10: 6, 7: 5, 15: 5, 17: 5, 2: 5, 12: 4, 1: 4, 19: 4, 3: 4, 5: 3, 9: 3, 6: 3, 11: 3, 18: 3, 0: 2})\n",
      "4 \t Counter({8: 111, 17: 99, 13: 98, 16: 98, 11: 97, 15: 95, 2: 94, 3: 92, 9: 88, 0: 88, 12: 88, 4: 87, 6: 84, 14: 79, 5: 78, 7: 76, 10: 74, 1: 74, 18: 67, 19: 61})\n",
      "5 \t Counter({12: 61, 2: 41, 6: 40, 11: 36, 10: 35, 4: 34, 5: 34, 9: 30, 8: 30, 7: 29, 14: 28, 3: 28, 1: 27, 17: 25, 15: 24, 18: 22, 13: 22, 0: 21, 19: 19, 16: 9})\n",
      "6 \t Counter({16: 3, 11: 3, 17: 2, 13: 2, 0: 2, 12: 2, 15: 2, 9: 2, 14: 2, 2: 2, 10: 2, 7: 1, 6: 1, 8: 1, 19: 1})\n",
      "7 \t Counter({10: 15, 6: 13, 1: 9, 15: 8, 17: 7, 9: 7, 2: 7, 12: 7, 11: 6, 3: 6, 7: 6, 19: 6, 13: 6, 18: 6, 4: 6, 8: 5, 14: 5, 0: 3, 5: 2, 16: 1})\n",
      "8 \t Counter({17: 4, 15: 3, 3: 2, 14: 2, 13: 2, 0: 2, 16: 1, 2: 1, 12: 1, 19: 1, 1: 1, 11: 1, 18: 1, 5: 1})\n",
      "9 \t Counter({2: 2, 19: 1, 17: 1, 3: 1, 11: 1, 18: 1})\n",
      "10 \t Counter({6: 12, 4: 10, 10: 8, 9: 8, 3: 6, 5: 6, 16: 6, 15: 6, 11: 6, 14: 5, 0: 5, 1: 5, 19: 5, 13: 4, 18: 4, 8: 4, 12: 3, 7: 2, 2: 1})\n",
      "11 \t Counter({7: 22, 9: 17, 8: 16, 14: 13, 17: 13, 4: 12, 2: 12, 16: 12, 11: 12, 10: 12, 18: 11, 13: 11, 6: 10, 5: 10, 15: 9, 12: 8, 19: 8, 3: 7, 0: 5, 1: 4})\n",
      "12 \t Counter({5: 16, 2: 9, 8: 8, 14: 7, 15: 7, 6: 6, 16: 5, 7: 5, 17: 5, 1: 5, 11: 4, 13: 4, 4: 3, 9: 3, 12: 3, 10: 3, 19: 3, 3: 2, 0: 2, 18: 1})\n",
      "13 \t Counter({10: 15, 9: 13, 6: 10, 16: 9, 15: 9, 14: 8, 12: 8, 11: 7, 0: 6, 7: 6, 19: 5, 13: 5, 1: 5, 3: 5, 5: 5, 18: 4, 4: 4, 8: 3, 2: 3, 17: 2})\n",
      "14 \t Counter({2: 88, 1: 83, 6: 83, 3: 80, 5: 58, 4: 57, 14: 45, 11: 42, 12: 39, 9: 36, 10: 32, 13: 32, 16: 27, 7: 26, 8: 24, 15: 15, 17: 14, 0: 13, 19: 11, 18: 9})\n",
      "15 \t Counter({15: 141, 7: 140, 17: 135, 13: 131, 9: 124, 10: 119, 14: 117, 12: 113, 8: 111, 16: 110, 11: 110, 1: 106, 4: 100, 0: 99, 18: 96, 2: 96, 3: 92, 19: 89, 5: 88, 6: 86})\n",
      "16 \t Counter({4: 20, 14: 10, 8: 10, 13: 9, 9: 9, 3: 8, 17: 8, 7: 8, 6: 8, 2: 7, 19: 7, 10: 7, 11: 7, 12: 6, 18: 6, 15: 6, 1: 5, 16: 5, 5: 5, 0: 5})\n",
      "17 \t Counter({5: 57, 4: 43, 11: 39, 2: 37, 15: 35, 1: 34, 10: 33, 13: 31, 16: 30, 3: 30, 18: 29, 7: 28, 14: 28, 12: 27, 6: 26, 0: 24, 17: 22, 8: 18, 9: 12, 19: 11})\n",
      "18 \t Counter({5: 31, 1: 21, 14: 17, 6: 16, 2: 15, 18: 15, 3: 15, 10: 14, 7: 14, 16: 14, 9: 13, 8: 13, 13: 12, 4: 11, 15: 10, 19: 10, 0: 10, 11: 9, 12: 9, 17: 5})\n",
      "19 \t Counter({8: 139, 13: 129, 15: 126, 11: 121, 9: 120, 14: 118, 7: 117, 10: 116, 16: 116, 1: 114, 17: 114, 5: 109, 3: 107, 4: 99, 18: 99, 12: 98, 0: 94, 2: 89, 6: 84, 19: 74})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "test_res = nmf_output['test-topic-document-matrix'].T\n",
    "pred = [np.argmax(res) for res in test_res]\n",
    "    \n",
    "temp = pd.DataFrame()\n",
    "temp['y_true'] = y_true\n",
    "temp['y_pred'] = pred\n",
    "for i in range(20):\n",
    "    print(i,'\\t',Counter(temp[temp['y_pred']==i]['y_true']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lerxstwamumdedu wheres thing subject car nntpp...</td>\n",
       "      <td>train</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guykuocarsonuwashingtonedu guy kuo subject si ...</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twillisececnpurdueedu thomas e willis subject ...</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jgreenamber joe green subject weitek p9000 org...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcmheadcfaharvardedu jonathan mcdowell subject...</td>\n",
       "      <td>train</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22623</th>\n",
       "      <td>jimzisfeinfactorycom jim zisfein subject migra...</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22624</th>\n",
       "      <td>ebodinpearltuftsedu subject screen death mac p...</td>\n",
       "      <td>test</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22625</th>\n",
       "      <td>westesnetcomcom estes subject mounting cpu coo...</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22626</th>\n",
       "      <td>stevehcrlgw steven collins subject sphere 4 po...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22627</th>\n",
       "      <td>gunningccocaltechedu kevin j gunning subject s...</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22628 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0      1   2\n",
       "0      lerxstwamumdedu wheres thing subject car nntpp...  train   7\n",
       "1      guykuocarsonuwashingtonedu guy kuo subject si ...  train   4\n",
       "2      twillisececnpurdueedu thomas e willis subject ...  train   4\n",
       "3      jgreenamber joe green subject weitek p9000 org...  train   1\n",
       "4      jcmheadcfaharvardedu jonathan mcdowell subject...  train  14\n",
       "...                                                  ...    ...  ..\n",
       "22623  jimzisfeinfactorycom jim zisfein subject migra...   test  13\n",
       "22624  ebodinpearltuftsedu subject screen death mac p...   test   4\n",
       "22625  westesnetcomcom estes subject mounting cpu coo...   test   3\n",
       "22626  stevehcrlgw steven collins subject sphere 4 po...   test   1\n",
       "22627  gunningccocaltechedu kevin j gunning subject s...   test   8\n",
       "\n",
       "[22628 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity Score: 0.07795651405338519\n",
      "NMI: 0.014185867877603306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       480\n",
      "           1       0.00      0.00      0.00       584\n",
      "           2       0.11      0.15      0.13       591\n",
      "           3       0.00      0.00      0.00       590\n",
      "           4       0.13      0.03      0.05       578\n",
      "           5       0.11      0.21      0.15       593\n",
      "           6       0.11      0.02      0.03       585\n",
      "           7       0.10      0.04      0.05       594\n",
      "           8       0.06      0.42      0.11       598\n",
      "           9       0.07      0.02      0.03       597\n",
      "          10       0.11      0.05      0.07       600\n",
      "          11       0.00      0.00      0.00       595\n",
      "          12       0.07      0.28      0.12       591\n",
      "          13       0.00      0.00      0.00       594\n",
      "          14       0.11      0.02      0.03       593\n",
      "          15       0.06      0.24      0.10       599\n",
      "          16       0.11      0.01      0.01       546\n",
      "          17       0.17      0.01      0.01       564\n",
      "          18       0.00      0.00      0.00       465\n",
      "          19       0.00      0.00      0.00       377\n",
      "\n",
      "    accuracy                           0.08     11314\n",
      "   macro avg       0.07      0.07      0.05     11314\n",
      "weighted avg       0.07      0.08      0.05     11314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patsias/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/patsias/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/patsias/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "topic_name={0:9,1:12,2:5,3:14,4:8,5:12,6:16,7:10,8:17,9:2,10:6,11:7,12:5,13:10,14:2,15:15,16:4,17:5,18:5,19:8}\n",
    "\n",
    "y_true = df[df[1]=='test'][2].to_list()\n",
    "y_pred = [*map(topic_name.get, pred)]\n",
    "\n",
    "q_metrics(y_true, pred)\n",
    "print(classification_report(y_true,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
