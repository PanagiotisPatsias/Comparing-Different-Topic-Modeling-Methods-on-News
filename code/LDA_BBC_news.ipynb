{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim\n",
    "from gensim.models.ldamodel import LdaModel as LDA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarne...</td>\n",
       "      <td>Ad sales boost Time Warner profit Quarterly pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against ...</td>\n",
       "      <td>Dollar gains on Greenspan speech The dollar ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuk...</td>\n",
       "      <td>Yukos unit buyer faces loan claim The owners o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices f...</td>\n",
       "      <td>High fuel prices hit BA's profits British Airw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Dome...</td>\n",
       "      <td>Pernod takeover talk lifts Domecq Shares in UK...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category filename                              title  \\\n",
       "0  business  001.txt  Ad sales boost Time Warner profit   \n",
       "1  business  002.txt   Dollar gains on Greenspan speech   \n",
       "2  business  003.txt  Yukos unit buyer faces loan claim   \n",
       "3  business  004.txt  High fuel prices hit BA's profits   \n",
       "4  business  005.txt  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                             content  \\\n",
       "0   Quarterly profits at US media giant TimeWarne...   \n",
       "1   The dollar has hit its highest level against ...   \n",
       "2   The owners of embattled Russian oil giant Yuk...   \n",
       "3   British Airways has blamed high fuel prices f...   \n",
       "4   Shares in UK drinks and food firm Allied Dome...   \n",
       "\n",
       "                                                text  label  \n",
       "0  Ad sales boost Time Warner profit Quarterly pr...      0  \n",
       "1  Dollar gains on Greenspan speech The dollar ha...      0  \n",
       "2  Yukos unit buyer faces loan claim The owners o...      0  \n",
       "3  High fuel prices hit BA's profits British Airw...      0  \n",
       "4  Pernod takeover talk lifts Domecq Shares in UK...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load Datasets\n",
    "# For BBC News dataset\n",
    "bbc_news = pd.read_csv(\"/home/patsias/Essential Text/Comparing-Different-Topic-Modeling-Methods-on-News/bbc-news-data.csv\",sep=\"\\t\")  \n",
    "bbc_news['text'] = bbc_news.apply(lambda r:r.title+r.content,axis=1).to_list()\n",
    "bbc_news['label'] = LabelEncoder().fit_transform(bbc_news['category']) \n",
    "\n",
    "bbc_news.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into Training and Test Sets \n",
    "### with a 20% Test Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(bbc_news, test_size=0.2, random_state=42)\n",
    "\n",
    "train['div'] = 'train'\n",
    "test['div'] = 'test'\n",
    "\n",
    "bbc_news_split = pd.concat([train, test],ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>div</th>\n",
       "      <th>category</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>business</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>politics</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>sport</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>tech</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train</td>\n",
       "      <td>business</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train</td>\n",
       "      <td>politics</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train</td>\n",
       "      <td>sport</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train</td>\n",
       "      <td>tech</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     div       category    0\n",
       "0   test       business  115\n",
       "1   test  entertainment   72\n",
       "2   test       politics   76\n",
       "3   test          sport  102\n",
       "4   test           tech   80\n",
       "5  train       business  395\n",
       "6  train  entertainment  314\n",
       "7  train       politics  341\n",
       "8  train          sport  409\n",
       "9  train           tech  321"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_news_split.groupby(['div','category']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/patsias/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation using regex\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text) \n",
    "\n",
    "    text = ' '.join(text.split())\n",
    "    # Tokenize words, remove stopwords, and convert back to string\n",
    "    words = text.split() \n",
    "    words = [word for word in words if word not in stop_words]  \n",
    "\n",
    "    return \" \".join(words)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_news_split['preprocessed_text'] = bbc_news_split['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_news_split['tok'] = bbc_news_split['preprocessed_text'].apply(lambda x: set(x.split()))\n",
    "\t\n",
    "\n",
    "train_docs = bbc_news_split[bbc_news_split['div']=='train']['tok'].to_numpy() \n",
    "dictionary = gensim.corpora.Dictionary(train_docs) \n",
    "\n",
    "bbc_news_split['corpus'] = [dictionary.doc2bow(doc) for doc in bbc_news_split['tok'].to_numpy()]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def q_metrics(y_true1, y_pred1):\n",
    "    contigency_matrix = metrics.cluster.contingency_matrix(y_true1, y_pred1)\n",
    "    purity = np.sum(np.amax(contigency_matrix, axis=0)) / np.sum(contigency_matrix)\n",
    "    print('purity_score:',purity)\n",
    "    print('NMI:',metrics.normalized_mutual_info_score(y_true1, y_pred1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Parameter Selection for Best Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 17.71 seconds\n",
      "Response Time: 0.10 seconds\n",
      "purity_score: 0.7033707865168539\n",
      "NMI: 0.5497146199720506\n",
      "Coherence Score: 0.2515690193383192\n",
      "i: 10 ; alpha: symmetric ; beta: auto\n",
      "Training Time: 17.71 seconds, Response Time: 0.10 seconds, Coherence Score: 0.2515690193383192\n",
      "\n",
      "Training Time: 15.63 seconds\n",
      "Response Time: 0.09 seconds\n",
      "purity_score: 0.7168539325842697\n",
      "NMI: 0.5826848693518991\n",
      "Coherence Score: 0.2879051648279455\n",
      "i: 10 ; alpha: symmetric ; beta: 0.4\n",
      "Training Time: 15.63 seconds, Response Time: 0.09 seconds, Coherence Score: 0.2879051648279455\n",
      "\n",
      "Training Time: 15.89 seconds\n",
      "Response Time: 0.10 seconds\n",
      "purity_score: 0.7213483146067415\n",
      "NMI: 0.5911339409905699\n",
      "Coherence Score: 0.2966718439488291\n",
      "i: 10 ; alpha: symmetric ; beta: 0.7\n",
      "Training Time: 15.89 seconds, Response Time: 0.10 seconds, Coherence Score: 0.2966718439488291\n",
      "\n",
      "Training Time: 16.12 seconds\n",
      "Response Time: 0.18 seconds\n",
      "purity_score: 0.7033707865168539\n",
      "NMI: 0.5497146199720506\n",
      "Coherence Score: 0.2554444516387922\n",
      "i: 10 ; alpha: 0.4 ; beta: auto\n",
      "Training Time: 16.12 seconds, Response Time: 0.18 seconds, Coherence Score: 0.2554444516387922\n",
      "\n",
      "Training Time: 16.07 seconds\n",
      "Response Time: 0.09 seconds\n",
      "purity_score: 0.7191011235955056\n",
      "NMI: 0.587677957730916\n",
      "Coherence Score: 0.2879051648279454\n",
      "i: 10 ; alpha: 0.4 ; beta: 0.4\n",
      "Training Time: 16.07 seconds, Response Time: 0.09 seconds, Coherence Score: 0.2879051648279454\n",
      "\n",
      "Training Time: 16.65 seconds\n",
      "Response Time: 0.10 seconds\n",
      "purity_score: 0.7213483146067415\n",
      "NMI: 0.5945077136065451\n",
      "Coherence Score: 0.30144725389676275\n",
      "i: 10 ; alpha: 0.4 ; beta: 0.7\n",
      "Training Time: 16.65 seconds, Response Time: 0.10 seconds, Coherence Score: 0.30144725389676275\n",
      "\n",
      "Training Time: 15.83 seconds\n",
      "Response Time: 0.10 seconds\n",
      "purity_score: 0.7033707865168539\n",
      "NMI: 0.5445831572533162\n",
      "Coherence Score: 0.2554444516387922\n",
      "i: 10 ; alpha: 0.7 ; beta: auto\n",
      "Training Time: 15.83 seconds, Response Time: 0.10 seconds, Coherence Score: 0.2554444516387922\n",
      "\n",
      "Training Time: 16.41 seconds\n",
      "Response Time: 0.11 seconds\n",
      "purity_score: 0.7191011235955056\n",
      "NMI: 0.5890913831641627\n",
      "Coherence Score: 0.26885321004700014\n",
      "i: 10 ; alpha: 0.7 ; beta: 0.4\n",
      "Training Time: 16.41 seconds, Response Time: 0.11 seconds, Coherence Score: 0.26885321004700014\n",
      "\n",
      "Training Time: 15.56 seconds\n",
      "Response Time: 0.10 seconds\n",
      "purity_score: 0.7213483146067415\n",
      "NMI: 0.5956608202832453\n",
      "Coherence Score: 0.28490914407306456\n",
      "i: 10 ; alpha: 0.7 ; beta: 0.7\n",
      "Training Time: 15.56 seconds, Response Time: 0.10 seconds, Coherence Score: 0.28490914407306456\n",
      "\n",
      "Training Time: 21.99 seconds\n",
      "Response Time: 0.17 seconds\n",
      "purity_score: 0.5865168539325842\n",
      "NMI: 0.4200328940546515\n",
      "Coherence Score: 0.2593058298123932\n",
      "i: 30 ; alpha: symmetric ; beta: auto\n",
      "Training Time: 21.99 seconds, Response Time: 0.17 seconds, Coherence Score: 0.2593058298123932\n",
      "\n",
      "Training Time: 22.50 seconds\n",
      "Response Time: 0.24 seconds\n",
      "purity_score: 0.698876404494382\n",
      "NMI: 0.515149106951409\n",
      "Coherence Score: 0.3323474761434744\n",
      "i: 30 ; alpha: symmetric ; beta: 0.4\n",
      "Training Time: 22.50 seconds, Response Time: 0.24 seconds, Coherence Score: 0.3323474761434744\n",
      "\n",
      "Training Time: 22.35 seconds\n",
      "Response Time: 0.17 seconds\n",
      "purity_score: 0.604494382022472\n",
      "NMI: 0.44737258877247227\n",
      "Coherence Score: 0.33668601834694434\n",
      "i: 30 ; alpha: symmetric ; beta: 0.7\n",
      "Training Time: 22.35 seconds, Response Time: 0.17 seconds, Coherence Score: 0.33668601834694434\n",
      "\n",
      "Training Time: 24.18 seconds\n",
      "Response Time: 0.19 seconds\n",
      "purity_score: 0.5932584269662922\n",
      "NMI: 0.42288157913049795\n",
      "Coherence Score: 0.2528243943569727\n",
      "i: 30 ; alpha: 0.4 ; beta: auto\n",
      "Training Time: 24.18 seconds, Response Time: 0.19 seconds, Coherence Score: 0.2528243943569727\n",
      "\n",
      "Training Time: 21.85 seconds\n",
      "Response Time: 0.23 seconds\n",
      "purity_score: 0.7146067415730337\n",
      "NMI: 0.521143128163077\n",
      "Coherence Score: 0.3323474761434744\n",
      "i: 30 ; alpha: 0.4 ; beta: 0.4\n",
      "Training Time: 21.85 seconds, Response Time: 0.23 seconds, Coherence Score: 0.3323474761434744\n",
      "\n",
      "Training Time: 22.73 seconds\n",
      "Response Time: 0.17 seconds\n",
      "purity_score: 0.6134831460674157\n",
      "NMI: 0.46466045642897097\n",
      "Coherence Score: 0.34665483198381963\n",
      "i: 30 ; alpha: 0.4 ; beta: 0.7\n",
      "Training Time: 22.73 seconds, Response Time: 0.17 seconds, Coherence Score: 0.34665483198381963\n",
      "\n",
      "Training Time: 23.25 seconds\n",
      "Response Time: 0.17 seconds\n",
      "purity_score: 0.6112359550561798\n",
      "NMI: 0.4329847551178947\n",
      "Coherence Score: 0.2483299987055294\n",
      "i: 30 ; alpha: 0.7 ; beta: auto\n",
      "Training Time: 23.25 seconds, Response Time: 0.17 seconds, Coherence Score: 0.2483299987055294\n",
      "\n",
      "Training Time: 23.11 seconds\n",
      "Response Time: 0.27 seconds\n",
      "purity_score: 0.7168539325842697\n",
      "NMI: 0.513743924950103\n",
      "Coherence Score: 0.33151587609876926\n",
      "i: 30 ; alpha: 0.7 ; beta: 0.4\n",
      "Training Time: 23.11 seconds, Response Time: 0.27 seconds, Coherence Score: 0.33151587609876926\n",
      "\n",
      "Training Time: 22.42 seconds\n",
      "Response Time: 0.18 seconds\n",
      "purity_score: 0.6337078651685393\n",
      "NMI: 0.4894141984435279\n",
      "Coherence Score: 0.3499444126243339\n",
      "i: 30 ; alpha: 0.7 ; beta: 0.7\n",
      "Training Time: 22.42 seconds, Response Time: 0.18 seconds, Coherence Score: 0.3499444126243339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "df = bbc_news_split\n",
    "\n",
    "def calculate_coherence_score(i, alpha, beta):\n",
    "    # Measure training time\n",
    "    start_train = time.time()\n",
    "    lda_result = LDA(corpus=df[df['div']=='train']['corpus'], id2word=dictionary,\n",
    "                     iterations=i, num_topics=TOPICS, \n",
    "                     chunksize=2000, random_state=42, gamma_threshold=0.001,\n",
    "                     passes=10, update_every=1,\n",
    "                     alpha=alpha, eta=beta)\n",
    "    end_train = time.time()\n",
    "    training_time = end_train - start_train\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    # Measure response time\n",
    "    start_response = time.time()\n",
    "    test_corpus_bow = df[df['div']=='test']['corpus'].to_numpy()\n",
    "    test_res = lda_result[test_corpus_bow]\n",
    "\n",
    "    # Get predictions for test set\n",
    "    pred = []\n",
    "    for x in test_res:\n",
    "        x = {k[0]: k[1] for k in x}\n",
    "        pred.append(max(x, key=x.get))\n",
    "    end_response = time.time()\n",
    "    response_time = end_response - start_response\n",
    "    print(f\"Response Time: {response_time:.2f} seconds\")\n",
    "\n",
    "    # Load true labels and calculate metrics\n",
    "    y_true = df[df['div']=='test']['label']\n",
    "    y_pred = pred\n",
    "    q_metrics(y_true, y_pred)\n",
    "\n",
    "    # Calculate and print coherence score\n",
    "    cm_lda = CoherenceModel(model=lda_result, dictionary=dictionary, \n",
    "                            corpus=df[(df['div']=='train')]['corpus'], \n",
    "                            texts=df[df['div']=='train']['tok'].to_numpy(), \n",
    "                            coherence='c_v')\n",
    "    coherence_lda = cm_lda.get_coherence()\n",
    "    print(f\"Coherence Score: {coherence_lda}\")\n",
    "\n",
    "    return training_time, response_time, coherence_lda\n",
    "\n",
    "# List of various hyperparameters\n",
    "no_of_iteration = [10, 30]\n",
    "alpha_list = ['symmetric', 0.4, 0.7]\n",
    "beta_list = ['auto', 0.4, 0.7]\n",
    "\n",
    "# Running the parameter grid search with timing\n",
    "for i in no_of_iteration:\n",
    "    for alpha in alpha_list:\n",
    "        for beta in beta_list:\n",
    "            training_time, response_time, coherence_lda = calculate_coherence_score(i, alpha, beta)\n",
    "            print(f\"i: {i} ; alpha: {alpha} ; beta: {beta}\")\n",
    "            print(f\"Training Time: {training_time:.2f} seconds, Response Time: {response_time:.2f} seconds, Coherence Score: {coherence_lda}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best params:\n",
    "\n",
    " i : 10 ; alpha : 'symmetric' ; beta : 0.7 \n",
    "\n",
    "purity_score: 0.721\\\n",
    "NMI: 0.591\\\n",
    "coherence_lda: 0.296"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity_score: 0.7213483146067415\n",
      "NMI: 0.5911339409905699\n",
      "coherence_lda: 0.2301904451522192\n"
     ]
    }
   ],
   "source": [
    "i= 10 ; alpha= 'symmetric' ; beta= 0.7\n",
    "df = bbc_news_split\n",
    "\n",
    "lda_result=LDA(corpus=df[(df['div']=='train')]['corpus'], id2word=dictionary,\n",
    "               iterations=i , num_topics=TOPICS,\n",
    "               chunksize=2000, random_state=42, gamma_threshold=0.001,\n",
    "               passes=10, update_every=1,\n",
    "               alpha=alpha,eta = beta)\n",
    "\n",
    "test_corpus_bow = df[df['div']=='test']['corpus'].to_numpy()\n",
    "test_res = lda_result[test_corpus_bow]\n",
    "\n",
    "pred_test=[]\n",
    "for x in test_res:\n",
    "    x={k[0]:k[1] for k in x}\n",
    "    pred_test.append(max(x,key=x.get) )\n",
    "\n",
    "y_true = df[df['div']=='test']['label'] \n",
    "y_pred = pred_test\n",
    "q_metrics(y_true, y_pred)\n",
    "\n",
    "\n",
    "# evaluate model using Topic Coherence score\n",
    "cm_lda = CoherenceModel(model=lda_result,\n",
    "                          dictionary=dictionary, \n",
    "                          corpus=df[(df['div']=='train')]['corpus'], \n",
    "                          texts=df[df['div']=='train']['tok'].to_numpy(), \n",
    "                          coherence='c_v')\n",
    "\n",
    "\n",
    "coherence_lda = cm_lda.get_coherence()\n",
    "print('coherence_lda:', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_bow = df[df['div']=='train']['corpus'].to_numpy()\n",
    "train_res = lda_result[train_corpus_bow]\n",
    "pred = []\n",
    "for x in train_res:\n",
    "    x = {k[0]: k[1] for k in x}\n",
    "    pred.append(max(x, key=x.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "  \n",
    "train_df = pd.DataFrame({\n",
    "    'topic': pred,\n",
    "    'label': bbc_news_split[bbc_news_split['div']=='train']['label']\n",
    "})\n",
    "\n",
    "train_topic_label_counts = train_df.groupby(['topic', 'label']).size().unstack(fill_value=0)\n",
    "topic_to_mode_label = train_df.groupby('topic')['label'].agg(lambda x: stats.mode(x)[0])\n",
    "\n",
    "mapped_test_labels = [topic_to_mode_label.get(topic, None) for topic in pred_test]\n",
    "\n",
    "test_results_df = pd.DataFrame({\n",
    "    'predicted_label': mapped_test_labels,\n",
    "    'true_label':bbc_news_split[bbc_news_split['div']=='test']['label']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       115\n",
      "           1       0.98      0.81      0.89        72\n",
      "           2       0.51      0.92      0.66        76\n",
      "           3       0.91      0.99      0.95       102\n",
      "           4       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.72       445\n",
      "   macro avg       0.61      0.70      0.64       445\n",
      "weighted avg       0.63      0.72      0.66       445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patsias/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/patsias/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/patsias/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_results_df['true_label'], test_results_df['predicted_label']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
