{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from octis.models.NMF import NMF\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BBC News dataset\n",
    "bbc_news = pd.read_csv(\"/home/patsias/Essential Text/Comparing-Different-Topic-Modeling-Methods-on-News/bbc-news-data.csv\", sep=\"\\t\")\n",
    "bbc_news['text'] = bbc_news['title'] + \" \" + bbc_news['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into Training and Test Sets \n",
    "### with a 20% Test Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "train, test = train_test_split(bbc_news, test_size=0.2, random_state=42)\n",
    "train['div'] = 'train'\n",
    "test['div'] = 'test'\n",
    "\n",
    "\n",
    "bbc_news_split = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>div</th>\n",
       "      <th>category</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>business</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>politics</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>sport</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>tech</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train</td>\n",
       "      <td>business</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train</td>\n",
       "      <td>politics</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train</td>\n",
       "      <td>sport</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train</td>\n",
       "      <td>tech</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     div       category    0\n",
       "0   test       business  115\n",
       "1   test  entertainment   72\n",
       "2   test       politics   76\n",
       "3   test          sport  102\n",
       "4   test           tech   80\n",
       "5  train       business  395\n",
       "6  train  entertainment  314\n",
       "7  train       politics  341\n",
       "8  train          sport  409\n",
       "9  train           tech  321"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_news_split.groupby(['div','category']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/patsias/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation using regex\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text) \n",
    "    text = ' '.join(text.split())\n",
    "    # Tokenize words, remove stopwords, and convert back to string\n",
    "    words = text.split() \n",
    "    words = [word for word in words if word not in stop_words]  \n",
    "\n",
    "    return \" \".join(words)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_news_split['preprocessed_text'] = bbc_news_split['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_news_split['tok'] = bbc_news_split['preprocessed_text'].apply(lambda x: set(x.split()))\n",
    "\t\n",
    "\n",
    "train_docs = bbc_news_split[bbc_news_split['div']=='train']['tok'].to_numpy() \n",
    "dictionary = gensim.corpora.Dictionary(train_docs) \n",
    "\n",
    "bbc_news_split['corpus'] = [dictionary.doc2bow(doc) for doc in bbc_news_split['tok'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def q_metrics(y_true1, y_pred1,my_model=None):\n",
    "    contigency_matrix = metrics.cluster.contingency_matrix(y_true1, y_pred1)\n",
    "    purity = np.sum(np.amax(contigency_matrix, axis=0)) / np.sum(contigency_matrix)\n",
    "    print('purity_score:',purity)\n",
    "    print('NMI:',metrics.normalized_mutual_info_score(y_true1, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.json has been successfully created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs('bbc_octis', exist_ok=True)\n",
    "\n",
    "# Save the vocabulary (for OCTIS)\n",
    "vocab_length = len(dictionary)\n",
    "with open(\"bbc_octis/vocabulary.txt\", \"w\", encoding='utf8') as f:\n",
    "    for i in range(vocab_length):\n",
    "        f.write(dictionary[i] + '\\n')\n",
    "\n",
    "# Create Bag-of-Words (BoW) representation\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in bbc_news_split['tok']]\n",
    "bbc_news_split['corpus'] = bow_corpus\n",
    "\n",
    "\n",
    "# Save the corpus as 'corpus.tsv'\n",
    "bbc_news_split[['preprocessed_text', 'div', 'category']].to_csv(\"bbc_octis/corpus.tsv\", sep='\\t', index=False, header=False)\n",
    "\n",
    "# Create metadata.json for categories\n",
    "labels = bbc_news_split['category'].tolist()\n",
    "\n",
    "# Write labels to metadata.json\n",
    "metadata = {\"labels\": labels}\n",
    "with open(\"bbc_octis/metadata.json\", \"w\") as outfile:\n",
    "    json.dump(metadata, outfile)\n",
    "\n",
    "print(\"metadata.json has been successfully created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Parameter Selection for Best Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity_score: 0.7033707865168539\n",
      "NMI: 0.4511664352718256\n",
      "Coherence Score: 0.4870866925406613\n",
      "w_max_iter : 50 ; kappa : 0.5 ; h_max_iter : 50 \n",
      "Training Time: 11.40 seconds, Response Time: 0.00 seconds, Coherence Score: 0.4870866925406613\n",
      "\n",
      "purity_score: 0.6786516853932584\n",
      "NMI: 0.4415069933786194\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 50 ; kappa : 1.0 ; h_max_iter : 50 \n",
      "Training Time: 10.62 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 50 ; kappa : 1.5 ; h_max_iter : 50 \n",
      "Training Time: 10.38 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.7033707865168539\n",
      "NMI: 0.4511664352718256\n",
      "Coherence Score: 0.4870866925406613\n",
      "w_max_iter : 50 ; kappa : 0.5 ; h_max_iter : 100 \n",
      "Training Time: 10.77 seconds, Response Time: 0.00 seconds, Coherence Score: 0.4870866925406613\n",
      "\n",
      "purity_score: 0.6674157303370787\n",
      "NMI: 0.41887778650781565\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 50 ; kappa : 1.0 ; h_max_iter : 100 \n",
      "Training Time: 13.48 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 50 ; kappa : 1.5 ; h_max_iter : 100 \n",
      "Training Time: 10.07 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.7033707865168539\n",
      "NMI: 0.4511664352718256\n",
      "Coherence Score: 0.4870866925406613\n",
      "w_max_iter : 50 ; kappa : 0.5 ; h_max_iter : 150 \n",
      "Training Time: 10.18 seconds, Response Time: 0.00 seconds, Coherence Score: 0.4870866925406613\n",
      "\n",
      "purity_score: 0.6898876404494382\n",
      "NMI: 0.44816846030651364\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 50 ; kappa : 1.0 ; h_max_iter : 150 \n",
      "Training Time: 10.10 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 50 ; kappa : 1.5 ; h_max_iter : 150 \n",
      "Training Time: 13.14 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.7033707865168539\n",
      "NMI: 0.4511664352718256\n",
      "Coherence Score: 0.4870866925406613\n",
      "w_max_iter : 50 ; kappa : 0.5 ; h_max_iter : 200 \n",
      "Training Time: 10.24 seconds, Response Time: 0.00 seconds, Coherence Score: 0.4870866925406613\n",
      "\n",
      "purity_score: 0.6696629213483146\n",
      "NMI: 0.42470061951246024\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 50 ; kappa : 1.0 ; h_max_iter : 200 \n",
      "Training Time: 10.33 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 50 ; kappa : 1.5 ; h_max_iter : 200 \n",
      "Training Time: 11.10 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6539325842696629\n",
      "NMI: 0.40086068799804764\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 100 ; kappa : 0.5 ; h_max_iter : 50 \n",
      "Training Time: 11.04 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6786516853932584\n",
      "NMI: 0.4415069933786194\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 100 ; kappa : 1.0 ; h_max_iter : 50 \n",
      "Training Time: 10.39 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 100 ; kappa : 1.5 ; h_max_iter : 50 \n",
      "Training Time: 10.46 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6539325842696629\n",
      "NMI: 0.40086068799804764\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 100 ; kappa : 0.5 ; h_max_iter : 100 \n",
      "Training Time: 12.03 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6674157303370787\n",
      "NMI: 0.41887778650781565\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 100 ; kappa : 1.0 ; h_max_iter : 100 \n",
      "Training Time: 13.96 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 100 ; kappa : 1.5 ; h_max_iter : 100 \n",
      "Training Time: 12.50 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6539325842696629\n",
      "NMI: 0.40086068799804764\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 100 ; kappa : 0.5 ; h_max_iter : 150 \n",
      "Training Time: 10.44 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6898876404494382\n",
      "NMI: 0.44816846030651364\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 100 ; kappa : 1.0 ; h_max_iter : 150 \n",
      "Training Time: 12.17 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 100 ; kappa : 1.5 ; h_max_iter : 150 \n",
      "Training Time: 10.44 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6539325842696629\n",
      "NMI: 0.40086068799804764\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 100 ; kappa : 0.5 ; h_max_iter : 200 \n",
      "Training Time: 17.41 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6696629213483146\n",
      "NMI: 0.42470061951246024\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 100 ; kappa : 1.0 ; h_max_iter : 200 \n",
      "Training Time: 15.88 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 100 ; kappa : 1.5 ; h_max_iter : 200 \n",
      "Training Time: 12.59 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6494382022471911\n",
      "NMI: 0.39235104038573754\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 150 ; kappa : 0.5 ; h_max_iter : 50 \n",
      "Training Time: 13.22 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6786516853932584\n",
      "NMI: 0.4415069933786194\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 150 ; kappa : 1.0 ; h_max_iter : 50 \n",
      "Training Time: 11.48 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 150 ; kappa : 1.5 ; h_max_iter : 50 \n",
      "Training Time: 11.07 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6494382022471911\n",
      "NMI: 0.39235104038573754\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 150 ; kappa : 0.5 ; h_max_iter : 100 \n",
      "Training Time: 11.15 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6674157303370787\n",
      "NMI: 0.41887778650781565\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 150 ; kappa : 1.0 ; h_max_iter : 100 \n",
      "Training Time: 11.01 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 150 ; kappa : 1.5 ; h_max_iter : 100 \n",
      "Training Time: 15.08 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6494382022471911\n",
      "NMI: 0.39235104038573754\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 150 ; kappa : 0.5 ; h_max_iter : 150 \n",
      "Training Time: 11.62 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6898876404494382\n",
      "NMI: 0.44816846030651364\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 150 ; kappa : 1.0 ; h_max_iter : 150 \n",
      "Training Time: 13.59 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 150 ; kappa : 1.5 ; h_max_iter : 150 \n",
      "Training Time: 11.27 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6494382022471911\n",
      "NMI: 0.39235104038573754\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 150 ; kappa : 0.5 ; h_max_iter : 200 \n",
      "Training Time: 11.12 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6696629213483146\n",
      "NMI: 0.42470061951246024\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 150 ; kappa : 1.0 ; h_max_iter : 200 \n",
      "Training Time: 13.85 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 150 ; kappa : 1.5 ; h_max_iter : 200 \n",
      "Training Time: 12.61 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6494382022471911\n",
      "NMI: 0.39235104038573754\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 200 ; kappa : 0.5 ; h_max_iter : 50 \n",
      "Training Time: 11.93 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6786516853932584\n",
      "NMI: 0.4415069933786194\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 200 ; kappa : 1.0 ; h_max_iter : 50 \n",
      "Training Time: 18.78 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 200 ; kappa : 1.5 ; h_max_iter : 50 \n",
      "Training Time: 12.45 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6494382022471911\n",
      "NMI: 0.39235104038573754\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 200 ; kappa : 0.5 ; h_max_iter : 100 \n",
      "Training Time: 11.19 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6674157303370787\n",
      "NMI: 0.41887778650781565\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 200 ; kappa : 1.0 ; h_max_iter : 100 \n",
      "Training Time: 10.82 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 200 ; kappa : 1.5 ; h_max_iter : 100 \n",
      "Training Time: 11.17 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6494382022471911\n",
      "NMI: 0.39235104038573754\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 200 ; kappa : 0.5 ; h_max_iter : 150 \n",
      "Training Time: 11.04 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6898876404494382\n",
      "NMI: 0.44816846030651364\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 200 ; kappa : 1.0 ; h_max_iter : 150 \n",
      "Training Time: 11.46 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 200 ; kappa : 1.5 ; h_max_iter : 150 \n",
      "Training Time: 11.06 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n",
      "purity_score: 0.6494382022471911\n",
      "NMI: 0.39235104038573754\n",
      "Coherence Score: 0.48576976434313635\n",
      "w_max_iter : 200 ; kappa : 0.5 ; h_max_iter : 200 \n",
      "Training Time: 12.47 seconds, Response Time: 0.00 seconds, Coherence Score: 0.48576976434313635\n",
      "\n",
      "purity_score: 0.6696629213483146\n",
      "NMI: 0.42470061951246024\n",
      "Coherence Score: 0.5436698981188819\n",
      "w_max_iter : 200 ; kappa : 1.0 ; h_max_iter : 200 \n",
      "Training Time: 10.62 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5436698981188819\n",
      "\n",
      "purity_score: 0.6022471910112359\n",
      "NMI: 0.30306942737919684\n",
      "Coherence Score: 0.5236676454036637\n",
      "w_max_iter : 200 ; kappa : 1.5 ; h_max_iter : 200 \n",
      "Training Time: 10.80 seconds, Response Time: 0.00 seconds, Coherence Score: 0.5236676454036637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def calculate_coherence_score(num_topics, kappa, w_max_iter, h_max_iter):\n",
    "    # Initialize model\n",
    "    model = NMF(num_topics=num_topics, chunksize=2000, passes=15, kappa=kappa,\n",
    "                minimum_probability=0.02, w_max_iter=w_max_iter,\n",
    "                w_stop_condition=0.0001, h_max_iter=h_max_iter, h_stop_condition=0.001,\n",
    "                eval_every=10, normalize=True, random_state=42)\n",
    "\n",
    "    # Load dataset\n",
    "    bbc_dataset = Dataset()\n",
    "    bbc_dataset.load_custom_dataset_from_folder('bbc_octis')\n",
    "\n",
    "    # Measure training time\n",
    "    start_train = time.time()\n",
    "    nmf_output = model.train_model(bbc_dataset)\n",
    "    end_train = time.time()\n",
    "    training_time = end_train - start_train\n",
    "\n",
    "    # Measure response time\n",
    "    start_response = time.time()\n",
    "    test_res = nmf_output['test-topic-document-matrix'].T\n",
    "    pred_test = [np.argmax(res) for res in test_res]\n",
    "    end_response = time.time()\n",
    "    response_time = end_response - start_response\n",
    " \n",
    "\n",
    "    # Load true labels from the dataset\n",
    "    df = pd.read_csv(\"bbc_octis/corpus.tsv\", sep='\\t', header=None)\n",
    "    y_true = df[df[1] == 'test'][2].values  \n",
    "\n",
    "    # Evaluate metrics\n",
    "    q_metrics(y_true, pred_test)\n",
    "\n",
    "    # Calculate Coherence\n",
    "    coherence = Coherence(texts=bbc_dataset.get_corpus(), topk=10, measure='c_v')\n",
    "    coherence_score = coherence.score(nmf_output)\n",
    "    print(f\"Coherence Score: {coherence_score}\")\n",
    "\n",
    "    return training_time, response_time, coherence_score\n",
    "\n",
    "\n",
    "# List containing various hyperparameters\n",
    "kappa = [0.5, 1.0, 1.5]\n",
    "w_max_iter = [50, 100, 150, 200]\n",
    "h_max_iter = [50, 100, 150, 200]\n",
    "\n",
    "for w in w_max_iter:\n",
    "    for h in h_max_iter:\n",
    "        for k in kappa:\n",
    "            training_time, response_time, coherence_score = calculate_coherence_score(num_topics=TOPICS, kappa=k, w_max_iter=w, h_max_iter=h)\n",
    "            print(f\"w_max_iter : {w} ; kappa : {k} ; h_max_iter : {h} \")\n",
    "            print(f\"Training Time: {training_time:.2f} seconds, Response Time: {response_time:.2f} seconds, Coherence Score: {coherence_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model\n",
    "### best parameter:\n",
    "w_max_iter = 50,  kappa = 0.5,  h_max_iter = 50 \\\n",
    "purity_score: 0.703 \\\n",
    "NMI: 0.451 \\\n",
    "Coherence Score: 0.487 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity_score: 0.7033707865168539\n",
      "NMI: 0.4511664352718256\n",
      "Coherence Score: 0.4870866925406613\n"
     ]
    }
   ],
   "source": [
    "w_max_iter = 50 ; kappa = 0.5 ; h_max_iter = 50\n",
    "model=NMF(num_topics=5, chunksize=2000, passes=15, kappa=kappa,\n",
    "                minimum_probability=0.02, w_max_iter=w_max_iter,\n",
    "                w_stop_condition=0.0001, h_max_iter= h_max_iter, h_stop_condition=0.001,\n",
    "                eval_every=10, normalize=True,random_state=42)\n",
    "\n",
    "bbc_dataset = Dataset()\n",
    "bbc_dataset.load_custom_dataset_from_folder('bbc_octis')\n",
    "nmf_output = model.train_model(bbc_dataset)\n",
    "\n",
    "test_res = nmf_output['test-topic-document-matrix'].T\n",
    "pred_test = [np.argmax(res) for res in test_res]\n",
    "\n",
    "# Load true labels from the dataset\n",
    "df = pd.read_csv(\"bbc_octis/corpus.tsv\", sep='\\t', header=None)\n",
    "y_true = df[df[1] == 'test'][2].values  # Assuming 2nd column is 'category'\n",
    "\n",
    "y_pred = pred_test\n",
    "q_metrics(y_true, y_pred)\n",
    "\n",
    "\n",
    "# evaluate model using Topic Coherence score\n",
    "coherence = Coherence(texts=bbc_dataset.get_corpus(), topk=10, measure='c_v')\n",
    "coherence_score = coherence.score(nmf_output)\n",
    "print(f\"Coherence Score: {coherence_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = nmf_output['topic-document-matrix'].T\n",
    "pred = [np.argmax(res) for res in train_res]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "  \n",
    "#Create a DataFrame for training data\n",
    "train_df = pd.DataFrame({\n",
    "    'topic': pred,\n",
    "    'label': bbc_news_split[bbc_news_split['div']=='train']['category']\n",
    "})\n",
    "\n",
    "#Group by 'topic' and count how many of each label there are for each topic in the training data\n",
    "train_topic_label_counts = train_df.groupby(['topic', 'label']).size().unstack(fill_value=0)\n",
    "\n",
    "#Assign the mode (most frequent label) for each topic in the training data\n",
    "topic_to_mode_label = train_df.groupby('topic')['label'].agg(lambda x: x.mode().iloc[0])\n",
    "\n",
    "#Map the predicted test topics to actual labels using the mapping from training data\n",
    "mapped_test_labels = [topic_to_mode_label.get(topic, None) for topic in pred_test]\n",
    "\n",
    "# Create a DataFrame to combine mapped test labels and actual test labels\n",
    "test_results_df = pd.DataFrame({\n",
    "    'predicted_label': mapped_test_labels,\n",
    "    'true_label':bbc_news_split[bbc_news_split['div']=='test']['category']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.53      0.82      0.64       115\n",
      "entertainment       0.90      0.50      0.64        72\n",
      "     politics       0.72      0.72      0.72        76\n",
      "        sport       0.86      0.84      0.85       102\n",
      "         tech       0.84      0.53      0.65        80\n",
      "\n",
      "     accuracy                           0.70       445\n",
      "    macro avg       0.77      0.68      0.70       445\n",
      " weighted avg       0.75      0.70      0.70       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report( test_results_df['true_label'],test_results_df['predicted_label']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
