{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laptop Path\n",
    "#source_path_for_bbc = r\"C:\\Users\\elias\\Documents\\NLP and speech processing\"\n",
    "#Desktop Path\n",
    "source_path_for_bbc = r\"C:\\Users\\super161\\Documents\\NLP and speech processing\"\n",
    "\n",
    "\n",
    "def process_folders(folder_path):\n",
    "    \n",
    "    documents_dict = {}\n",
    "    document_list = []\n",
    "    for folder_name in os.listdir(folder_path):\n",
    "        folder_full_path = os.path.join(folder_path, folder_name)\n",
    "        documents_dict[folder_name] = []\n",
    "        \n",
    "        for document_name in os.listdir(folder_full_path):\n",
    "            document_full_path = os.path.join(folder_full_path, document_name)\n",
    "            \n",
    "            # Open and read the content of each document\n",
    "            with open(document_full_path, 'r', encoding='utf-8') as file:\n",
    "                document_content = file.read()\n",
    "            document_list.append((folder_name, document_content, document_name))\n",
    "        \n",
    "    bbc_news = pd.DataFrame(document_list, columns = ['category', 'content', 'name'])\n",
    "\n",
    "    train, test = train_test_split(bbc_news, test_size=0.2)\n",
    "\n",
    "    train = train.sort_values(by='category')\n",
    "    train_first_doc = train.groupby('category').first().reset_index()\n",
    "\n",
    "    train_first_doc['div'] = 'train'\n",
    "    test['div'] = 'test'\n",
    "\n",
    "\n",
    "    return test, train_first_doc\n",
    "\n",
    "#Data Structure: Topic, Article Text\n",
    "\n",
    "test_df, instruction_df = process_folders(source_path_for_bbc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['bbc_tech_203.txt'])\n"
     ]
    }
   ],
   "source": [
    "def make_prompts(bbc_instructions, bbc_data):\n",
    "    prompts = []\n",
    "    \n",
    "    # General instructions and fixed texts\n",
    "    general_instruction = (\n",
    "        \"You are a perfect topic modeling machine. Given a text and the different topics, \"\n",
    "        \"you will classify the texts to the correct topic. First you will receive the topics, \"\n",
    "        \"afterwards an example and finally the text you have to assign one of the before mentioned topics to.\"\n",
    "    )\n",
    "    topics = \"The topics are business, entertainment, politics, sport and tech. Please make sure, you know the topics and their meaning.\"\n",
    "    transition_to_examples = \"Now an example for each of the categories will follow.\"\n",
    "    transition_to_text_to_classify = (\n",
    "        \"Now the text, you have to classify will follow. Please assess its topic and answer only the topic of it.\"\n",
    "    )\n",
    "\n",
    "    # Iterate through the test DataFrame rows\n",
    "    for _, test_row in bbc_data.iterrows():\n",
    "        prompt = general_instruction + \"\\n\" + topics + \"\\n\" + transition_to_examples + \"\\n\"\n",
    "\n",
    "        # Iterate through instruction DataFrame to add examples\n",
    "        for _, instruction_row in bbc_instructions.iterrows():\n",
    "            category = instruction_row['category']\n",
    "            example_text = instruction_row['content']\n",
    "            prompt += f\"For the following text: \\n{example_text}\\nThe correct answer would be: {category}\\n\"\n",
    "\n",
    "        # Add the actual text to classify from the test set\n",
    "        text_to_classify = test_row['content']\n",
    "        prompt += transition_to_text_to_classify + \"\\n\" + text_to_classify + \"\\n\"\n",
    "        name = f\"bbc_{test_row['category']}_{test_row['name']}\"\n",
    "        #print(name)\n",
    "        prompt_dict = {}\n",
    "        prompt_dict[name] = prompt\n",
    "        prompts.append(prompt_dict)\n",
    "    return prompts            \n",
    "\n",
    "prompts = make_prompts(instruction_df, test_df)\n",
    "prompts = prompts[:11]\n",
    "print(prompts[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "semaphore = asyncio.Semaphore(10)\n",
    "\n",
    "async def prompt_llm(prompt,  time_interval):\n",
    "    async with semaphore:\n",
    "        name = list(prompt.keys())[0]\n",
    "        promptAI = prompt[name]   \n",
    "\n",
    "        generation_config = {\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 64,\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "        }\n",
    "        model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-pro\",\n",
    "        generation_config=generation_config,\n",
    "        safety_settings = {HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE},\n",
    "        )\n",
    "        \n",
    "        chat_session = model.start_chat(\n",
    "        history=[\n",
    "        ]\n",
    "        )\n",
    "        answer = chat_session.send_message(promptAI)\n",
    "        text_response = answer._result.candidates[0].content.parts[0].text\n",
    "        await asyncio.sleep(time_interval)\n",
    "        \n",
    "        return {name : text_response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bbc_tech_203.txt': 'entertainment \\n'}, {'bbc_sport_121.txt': 'sport \\n'}, {'bbc_politics_114.txt': 'politics \\n'}, {'bbc_sport_168.txt': 'sport \\n'}, {'bbc_business_144.txt': 'business \\n'}, {'bbc_business_360.txt': 'business \\n'}, {'bbc_entertainment_385.txt': 'entertainment \\n'}, {'bbc_entertainment_012.txt': 'entertainment \\n'}, {'bbc_sport_272.txt': 'sport \\n'}, {'bbc_business_240.txt': 'business \\n'}, {'bbc_tech_140.txt': 'sport \\n'}]\n",
      "[{'bbc_tech_203.txt': 'entertainment \\n'}, {'bbc_sport_121.txt': 'sport \\n'}, {'bbc_politics_114.txt': 'politics \\n'}, {'bbc_sport_168.txt': 'sport \\n'}, {'bbc_business_144.txt': 'business \\n'}, {'bbc_business_360.txt': 'business \\n'}, {'bbc_entertainment_385.txt': 'entertainment \\n'}, {'bbc_entertainment_012.txt': 'entertainment \\n'}, {'bbc_sport_272.txt': 'sport \\n'}, {'bbc_business_240.txt': 'business \\n'}, {'bbc_tech_140.txt': 'sport \\n'}]\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "async def prompt_orchestrator():\n",
    "      batch_size = 5\n",
    "      batches = [prompts[i:i + batch_size] for i in range(0, len(prompts), batch_size)]\n",
    "\n",
    "      # Ensure the last batch is smaller if it's less than batch_size\n",
    "      if len(batches[-1]) < batch_size:\n",
    "            remaining = len(batches[-1])\n",
    "            batches[-1] = prompts[-remaining:]\n",
    "\n",
    "      # If the last batch is part of the earlier slices and it's less than batch_size\n",
    "      if len(prompts) % batch_size != 0:\n",
    "            remaining = len(prompts) % batch_size\n",
    "            batches[-1] = prompts[-remaining:]\n",
    "\n",
    "      time_interval = 60 / 300\n",
    "      avatiables = []\n",
    "\n",
    "      for batch in batches:\n",
    "            avatiables_batch = await asyncio.gather(*(prompt_llm(prompt, time_interval) for prompt in batch))\n",
    "            avatiables.extend(avatiables_batch) \n",
    "      print(avatiables)\n",
    "      return avatiables\n",
    "results = await prompt_orchestrator()\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
